/* Generated by RuntimeBrowser
   Image: /System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
 */

@interface CSHybridEndpointAnalyzer : NSObject <CSAssetManagerDelegate, CSEndpointAnalyzerImpl, EARCaesuraSilencePosteriorGeneratorDelegate> {
    unsigned long long  _activeChannel;
    NSObject<OS_dispatch_queue> * _apQueue;
    double  _automaticEndpointingSuspensionEndTime;
    EARCaesuraSilencePosteriorGenerator * _caesuraSPG;
    bool  _canProcessCurrentRequest;
    double  _clampedSFLatencyMsForClientLag;
    double  _clientLagThresholdMs;
    EARClientSilenceFeatures * _clientSilenceFeaturesAtEndpoint;
    CSAsset * _currentAsset;
    unsigned long long  _currentRequestSampleRate;
    double  _delay;
    <CSEndpointAnalyzerDelegate> * _delegate;
    bool  _didAddAudio;
    bool  _didCommunicateEndpoint;
    bool  _didDetectSpeech;
    bool  _didReceiveServerFeatures;
    bool  _didTimestampFirstAudioPacket;
    double  _elapsedTimeWithNoSpeech;
    double  _endWaitTime;
    long long  _endpointMode;
    long long  _endpointStyle;
    NSString * _endpointerModelVersion;
    NSDate * _firstAudioPacketTimestamp;
    double  _hepAudioOriginInMs;
    _EAREndpointer * _hybridClassifier;
    NSObject<OS_dispatch_queue> * _hybridClassifierQueue;
    double  _interspeechWaitTime;
    CSServerEndpointFeatures * _lastKnownServerEPFeatures;
    double  _lastReportedEndpointTimeMs;
    NSDate * _lastServerFeatureTimestamp;
    double  _minimumDurationForEndpointer;
    unsigned long long  _numSamplesProcessed;
    NSDictionary * _recordContext;
    bool  _recordingDidStop;
    bool  _saveSamplesSeenInReset;
    NSMutableArray * _serverFeatureLatencies;
    NSObject<OS_dispatch_queue> * _serverFeaturesQueue;
    double  _serverFeaturesWarmupLatency;
    NSObject<OS_dispatch_queue> * _silencePosteriorGeneratorQueue;
    double  _startWaitTime;
    NSObject<OS_dispatch_queue> * _stateSerialQueue;
    double  _trailingSilenceDurationAtEndpoint;
    bool  _useDefaultServerFeaturesOnClientLag;
    unsigned long long  _vtEndInSampleCount;
    double  _vtExtraAudioAtStartInMs;
}

@property (nonatomic) unsigned long long activeChannel;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *apQueue;
@property (nonatomic) double automaticEndpointingSuspensionEndTime;
@property (nonatomic) double bypassSamples;
@property (nonatomic, retain) EARCaesuraSilencePosteriorGenerator *caesuraSPG;
@property (nonatomic) bool canProcessCurrentRequest;
@property (nonatomic) double clampedSFLatencyMsForClientLag;
@property (nonatomic) double clientLagThresholdMs;
@property (nonatomic, retain) EARClientSilenceFeatures *clientSilenceFeaturesAtEndpoint;
@property (nonatomic, retain) CSAsset *currentAsset;
@property (nonatomic) unsigned long long currentRequestSampleRate;
@property (readonly, copy) NSString *debugDescription;
@property (nonatomic) double delay;
@property (nonatomic) <CSEndpointAnalyzerDelegate> *delegate;
@property (readonly, copy) NSString *description;
@property (nonatomic) bool didAddAudio;
@property (nonatomic) bool didCommunicateEndpoint;
@property (nonatomic) bool didDetectSpeech;
@property (nonatomic) bool didReceiveServerFeatures;
@property (nonatomic) bool didTimestampFirstAudioPacket;
@property (nonatomic) double elapsedTimeWithNoSpeech;
@property (nonatomic) double endWaitTime;
@property (nonatomic) long long endpointMode;
@property (nonatomic) long long endpointStyle;
@property (nonatomic, retain) NSString *endpointerModelVersion;
@property (nonatomic, retain) NSDate *firstAudioPacketTimestamp;
@property (readonly) unsigned long long hash;
@property (nonatomic) double hepAudioOriginInMs;
@property (nonatomic, retain) _EAREndpointer *hybridClassifier;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *hybridClassifierQueue;
@property (nonatomic) double interspeechWaitTime;
@property (nonatomic, readonly) double lastEndOfVoiceActivityTime;
@property (nonatomic, retain) CSServerEndpointFeatures *lastKnownServerEPFeatures;
@property (nonatomic) double lastReportedEndpointTimeMs;
@property (nonatomic, retain) NSDate *lastServerFeatureTimestamp;
@property (nonatomic, readonly) double lastStartOfVoiceActivityTime;
@property (nonatomic) double minimumDurationForEndpointer;
@property (nonatomic) unsigned long long numSamplesProcessed;
@property (nonatomic, retain) NSDictionary *recordContext;
@property (nonatomic) bool recordingDidStop;
@property (nonatomic) bool saveSamplesSeenInReset;
@property (nonatomic, retain) NSMutableArray *serverFeatureLatencies;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *serverFeaturesQueue;
@property (nonatomic) double serverFeaturesWarmupLatency;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *silencePosteriorGeneratorQueue;
@property (nonatomic) double startWaitTime;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *stateSerialQueue;
@property (readonly) Class superclass;
@property (nonatomic) double trailingSilenceDurationAtEndpoint;
@property (nonatomic) bool useDefaultServerFeaturesOnClientLag;
@property (nonatomic) unsigned long long vtEndInSampleCount;
@property (nonatomic) double vtExtraAudioAtStartInMs;

- (void).cxx_destruct;
- (void)CSAssetManagerDidDownloadNewAsset:(id)arg1;
- (void)CSLanguageCodeUpdateMonitor:(id)arg1 didReceiveLanguageCodeChanged:(id)arg2;
- (id)_getCSHybridEndpointerConfigForAsset:(id)arg1;
- (void)_readClientLagParametersFromHEPAsset:(id)arg1;
- (void)_updateAssetWithCurrentLanguage;
- (void)_updateAssetWithLanguage:(id)arg1;
- (unsigned long long)activeChannel;
- (id)apQueue;
- (double)automaticEndpointingSuspensionEndTime;
- (id)caesuraSPG;
- (bool)canProcessCurrentRequest;
- (double)clampedSFLatencyMsForClientLag;
- (double)clientLagThresholdMs;
- (id)clientSilenceFeaturesAtEndpoint;
- (void)clientSilenceFeaturesAvailable:(id)arg1;
- (id)currentAsset;
- (unsigned long long)currentRequestSampleRate;
- (double)delay;
- (id)delegate;
- (bool)didAddAudio;
- (bool)didCommunicateEndpoint;
- (bool)didDetectSpeech;
- (bool)didReceiveServerFeatures;
- (bool)didTimestampFirstAudioPacket;
- (double)elapsedTimeWithNoSpeech;
- (double)endWaitTime;
- (long long)endpointMode;
- (long long)endpointStyle;
- (id)endpointerModelVersion;
- (id)firstAudioPacketTimestamp;
- (void)handleVoiceTriggerWithActivationInfo:(id)arg1;
- (double)hepAudioOriginInMs;
- (id)hybridClassifier;
- (id)hybridClassifierQueue;
- (id)init;
- (double)interspeechWaitTime;
- (double)lastEndOfVoiceActivityTime;
- (id)lastKnownServerEPFeatures;
- (double)lastReportedEndpointTimeMs;
- (id)lastServerFeatureTimestamp;
- (double)lastStartOfVoiceActivityTime;
- (double)minimumDurationForEndpointer;
- (unsigned long long)numSamplesProcessed;
- (void)preheat;
- (void)processAudioSamplesAsynchronously:(id)arg1;
- (void)processServerEndpointFeatures:(id)arg1;
- (id)recordContext;
- (bool)recordingDidStop;
- (void)recordingStoppedForReason:(unsigned long long)arg1;
- (void)reset;
- (void)resetForNewRequestWithSampleRate:(unsigned long long)arg1 recordContext:(id)arg2;
- (bool)saveSamplesSeenInReset;
- (id)serverFeatureLatencies;
- (id)serverFeaturesLatencyDistributionDictionary;
- (id)serverFeaturesQueue;
- (double)serverFeaturesWarmupLatency;
- (void)setActiveChannel:(unsigned long long)arg1;
- (void)setApQueue:(id)arg1;
- (void)setAutomaticEndpointingSuspensionEndTime:(double)arg1;
- (void)setCaesuraSPG:(id)arg1;
- (void)setCanProcessCurrentRequest:(bool)arg1;
- (void)setClampedSFLatencyMsForClientLag:(double)arg1;
- (void)setClientLagThresholdMs:(double)arg1;
- (void)setClientSilenceFeaturesAtEndpoint:(id)arg1;
- (void)setCurrentAsset:(id)arg1;
- (void)setCurrentRequestSampleRate:(unsigned long long)arg1;
- (void)setDelay:(double)arg1;
- (void)setDelegate:(id)arg1;
- (void)setDidAddAudio:(bool)arg1;
- (void)setDidCommunicateEndpoint:(bool)arg1;
- (void)setDidDetectSpeech:(bool)arg1;
- (void)setDidReceiveServerFeatures:(bool)arg1;
- (void)setDidTimestampFirstAudioPacket:(bool)arg1;
- (void)setElapsedTimeWithNoSpeech:(double)arg1;
- (void)setEndWaitTime:(double)arg1;
- (void)setEndpointMode:(long long)arg1;
- (void)setEndpointStyle:(long long)arg1;
- (void)setEndpointerModelVersion:(id)arg1;
- (void)setFirstAudioPacketTimestamp:(id)arg1;
- (void)setHepAudioOriginInMs:(double)arg1;
- (void)setHybridClassifier:(id)arg1;
- (void)setHybridClassifierQueue:(id)arg1;
- (void)setInterspeechWaitTime:(double)arg1;
- (void)setLastKnownServerEPFeatures:(id)arg1;
- (void)setLastReportedEndpointTimeMs:(double)arg1;
- (void)setLastServerFeatureTimestamp:(id)arg1;
- (void)setMinimumDurationForEndpointer:(double)arg1;
- (void)setNumSamplesProcessed:(unsigned long long)arg1;
- (void)setRecordContext:(id)arg1;
- (void)setRecordingDidStop:(bool)arg1;
- (void)setSaveSamplesSeenInReset:(bool)arg1;
- (void)setServerFeatureLatencies:(id)arg1;
- (void)setServerFeaturesQueue:(id)arg1;
- (void)setServerFeaturesWarmupLatency:(double)arg1;
- (void)setSilencePosteriorGeneratorQueue:(id)arg1;
- (void)setStartWaitTime:(double)arg1;
- (void)setStateSerialQueue:(id)arg1;
- (void)setTrailingSilenceDurationAtEndpoint:(double)arg1;
- (void)setUseDefaultServerFeaturesOnClientLag:(bool)arg1;
- (void)setVtEndInSampleCount:(unsigned long long)arg1;
- (void)setVtExtraAudioAtStartInMs:(double)arg1;
- (void)shouldAcceptEagerResultForDuration:(double)arg1 resultsCompletionHandler:(id /* block */)arg2;
- (id)silencePosteriorGeneratorQueue;
- (double)startWaitTime;
- (id)stateSerialQueue;
- (double)trailingSilenceDurationAtEndpoint;
- (void)updateEndpointerDelayedTrigger:(bool)arg1;
- (void)updateEndpointerThreshold:(float)arg1;
- (bool)useDefaultServerFeaturesOnClientLag;
- (unsigned long long)vtEndInSampleCount;
- (double)vtExtraAudioAtStartInMs;

@end
