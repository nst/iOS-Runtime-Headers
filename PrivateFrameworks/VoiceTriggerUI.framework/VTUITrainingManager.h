/* Generated by RuntimeBrowser
   Image: /System/Library/PrivateFrameworks/VoiceTriggerUI.framework/VoiceTriggerUI
 */

@interface VTUITrainingManager : NSObject <AFAudioAnalyzerDelegate, VTUIAudioSessionDelegate, VTUITrainingSessionDelegate> {
    AFAudioAnalyzer * _audioAnalyzer;
    <VTUIAudioSession> * _audioSession;
    id  _cleanupCompletion;
    VTUITrainingSession * _currentTrainingSession;
    <VTUITrainingManagerDelegate> * _delegate;
    NSString * _locale;
    bool  _performRMS;
    VTPhraseSpotter * _phraseSpotter;
    NSObject<OS_dispatch_queue> * _queue;
    float  _rms;
    long long  _sessionNumber;
    SFSpeechRecognizer * _speechRecognizer;
    bool  _speechRecognizerAvailable;
    bool  _suspendAudio;
    NSMutableArray * _trainingSessions;
}

@property (readonly) int audioSource;
@property (readonly, copy) NSString *debugDescription;
@property (nonatomic) <VTUITrainingManagerDelegate> *delegate;
@property (readonly, copy) NSString *description;
@property (readonly) unsigned long long hash;
@property float rms;
@property (readonly) bool speechRecognizerAvailable;
@property (readonly) Class superclass;
@property bool suspendAudio;

+ (id)sharedtrainingSessionQueue;
+ (id)trainingManagerWithLocaleID:(id)arg1;

- (void).cxx_destruct;
- (void)VTUITrainingSessionRMSAvailable:(float)arg1;
- (void)VTUITrainingSessionStopListen;
- (void)_beginOfSpeechDetected;
- (void)_endOfSpeechDetected;
- (void)audioAnalyzer:(id)arg1 didDetectHardEndpointAtTime:(double)arg2;
- (void)audioAnalyzer:(id)arg1 didDetectStartpointAtTime:(double)arg2;
- (void)audioSessionDidStartRecording:(bool)arg1 error:(id)arg2;
- (void)audioSessionDidStopRecording:(long long)arg1;
- (void)audioSessionErrorDidOccur:(id)arg1;
- (void)audioSessionRecordBufferAvailable:(id)arg1;
- (void)audioSessionUnsupportedAudioRoute;
- (int)audioSource;
- (bool)cancelTrainingForID:(long long)arg1;
- (id)cleanupWithCompletion:(id)arg1;
- (void)closeSessionBeforeStartWithStatus:(int)arg1 successfully:(bool)arg2 withCompletion:(id)arg3;
- (bool)createAudioAnalyzer;
- (void)createSpeechRecognizer;
- (bool)createVoiceTrigger;
- (id)delegate;
- (void)destroyAudioSession;
- (void)destroyVoiceTrigger;
- (void)didDetectForceEndPoint;
- (id)initWithLocaleIdentifier:(id)arg1 withAudioSession:(id)arg2;
- (void)reset;
- (float)rms;
- (void)setDelegate:(id)arg1;
- (void)setLocaleIdentifier:(id)arg1;
- (void)setRms:(float)arg1;
- (void)setSuspendAudio:(bool)arg1;
- (bool)setupAudioSession;
- (bool)shouldPerformRMS;
- (bool)shouldShowHeadsetDisconnectionMessage;
- (bool)speechRecognizerAvailable;
- (bool)startAudioSession;
- (void)startRMS;
- (void)stopAudioSession;
- (void)stopRMS;
- (bool)suspendAudio;
- (long long)trainUtterance:(long long)arg1 shouldUseASR:(bool)arg2 completion:(id)arg3;

@end
